# TAG Privacy TF - Wed, 12 April 2023

Present: Dan, Amy, Nick, Robin (async), Jeffrey, Wendy, Sam, Christine
Regrets: Pete, Don

## [PR: Identify what makes print less likely to violate group privacy than the web](https://github.com/w3ctag/privacy-principles/pull/248)

J: Robin approved... Michael Kleber is still worried about it... Not entirely sure what to suggest... 

Dan: so the PR is a step forward but let's not close the issue?

J: probably true.  Robin's comment is on seeking relief.  We were overstating the case.. 

Wendy: I think I don't agree that readers of a print publication are implicitly having their data processed if there's no feedback looop. It may be that subscribers to a publication are but someone who buys it off the newsstand not...

J: argument: even peoiple who opted out of data collection are members of this group which opted into data collection... 

W: a reader whose IP address is communicating some info... a reader who purchases off the newsstand isn't communcating even that... Buying a group good but not divulging any info about yourself.

Nick: inappropriateness to the targetting separate to the data collection... red-lining or those types of things can be inappropriate... even if you didn't know a certain fact about an individual...

J: could be data processing is wrong term...

N: I think data processing was in there because ... of previous text .. mighg prefer that we say "things can be inappropriate and violate privacy without individual data processing". Also there can be things that are inappropriate without our document ... 

J: choosing not to buy ads in a magazine is OK. advertisers don't have an obligation to buy ads absolutely everywhere... the basic idea is correct.

Nick: would michael & people raising this accept that it's inappropriate and discrimitory... 

J: Wendy's right that there can also be wrongs that are not privacy problems... Maybe the issue that group membership may not be obvious to the members of the group...

W: the issues of algorithmic discrimination and real time targeting tweaks is all interesting but maybe too far for us to parse out here

J: there's a risk of us inventing too much

D: I'm trying to claw back what are we trying to achieve here? Could we solve this problem by reducing the text?

J: this whole section is an extension of what's in the academic literature. Which says basically sometimes group and individual privacy are in conflict. We're extending that to a particular point about advertising, but maybe we shouldn't.

D: From user needs of this document... is something we're saying going to be useful to the consumers of this document? It was useful to be able to say just because some aspect of print media is this way doesn't mean it's okay.. some privacy violation exists in print media doesn't mean we need to replicate that in online media. But I don't think we're trying to say that. What's useful to api designers?

J: My change in the later paragraph gets at something practically useful for api reviewers. Maybe we can cut away anything earlier than that that isn't needed to motivate that piece. That web standards help by ensuring researchers and regulators can discover group level abuse. Has practical implications for some of the privacy sandbox apis.

D: the part we cut back on is the example?

j: yes. Delete the example?

D: yes

J: should run it by Robin

N: I'd like to come up with some example and eventually guidence forline drawing where we say certain targeting of groups is inappropriate and violates privacy, even though we won't always be able to address it that's something to consider. No bright line for that. Becomes more clear on smaller groups, if you don't know exactly some fact about me but .. if the teacher of a class learns that three students are reading websites about abortion healthcare, that might not reveal any individual facts, but targeting something to that small group might still be a violation of privacy

D: new issue for this? for a more nuanced example?

N: sure

## [PR 250](https://github.com/w3ctag/privacy-principles/pull/250) vs [PR 245](https://github.com/w3ctag/privacy-principles/pull/245)

D: what was the objection to this reference?

J: we talk about fiduciary, but only cite a non academic article. Wendy suggested an article that introduces the use of "information fiduciaries" so I replaced the non-academic article with that. Robin adds that and a fiduciary law review that I think Wendy had cited last week, and still cites his (non-academic) article. I'm worried the fiduciary law one doesn't talk about information fiduciaries so it's not really evidence for this sentence. I don't know we've really reviewed Robin's article, so it's his words without review

D: sounds like Robin's suggestion is addative to your suggestion

J: my suggestion removes the citation to his article so I don't know that he would agree mine is good by itself

W: I'm fine with either. Both seem to be improvements on where we are

C: [one from the Canadian bar](https://www.cba.org/Sections/Privacy-and-Access/Resources/Resources/2021/PrivacyEssayWinner2021)

J: no opinion about which to cite as long as they are academic and reviewed

N: technically law review articles don't go thorugh peer review

J: they get reviewed by editors?

N: yes

D: how do you feel about merging Robin's PR?

J: improvement on existing text. No strong objection. Rather others make a call.

D: I suggest we merge #250

A: do we apply this standard to all of our citations?

J: we haven't reviewed. It would be a nice standard to apply. Concern that it's also by a member of the group

D: this taskforce is composed of experts, I think it's okay

N: we cite something by Tess, and multiple law review articles that aren't technically peer reviewed.

D: it's encumbant on all of us to scrutinise the references

W: citation doesn't imply endorsement

J: this is fine

D: [merges #250]

## [PR #243: ..not about GDPR](https://github.com/w3ctag/privacy-principles/pull/243)

D: i think that works. 

J: approve

## [PR 249: safety systems](https://github.com/w3ctag/privacy-principles/pull/249)

J: Robin wanted statement weaker, internal review wanted stronger

Sam: I like the original text

J: two orthogonal changes.. systesm don't have to disclose how they detect fraud. That change is important. Second piece is saying it's okay for people to do that. I expect that's more controversial

N: I think I understand the motivation that you're not going to explain in detail how you're doing fraud prevention.. but even your change still says a service should explain what data it's using for this purpose

J: explaining we're collecting your IP address is different from saying if we see 73 requests from that address within an hour we think it's fraud

N: I didn't think the original text implied that..

J: i wanted to make sure it can't be interpreted that way

N: my concern was not so much about use of "legitimate" but that you should compare the amount of risk and amount of protection as if these are quantities that can be compared

J: I didn't want to just say as long as it's reasonable.. too much of a blank cheque, but wasn't sure exactly what to say. When is it okay?

Sam: is it okay for them to decide tha treasonableness on their own? and not explain it? at what point is it okay behind closed doors?

J: the two major privacy laws have this carveout.. strictly necessary for detecting or protecting against fraud. GDPR says strictly  necessary, but CCPA is pretty blanket. I'm open to whatever restrictions we want to write. I'm hoping we can say a reasonable purpose in general as long as it's done reasonably

Sam: this is too blank of a cheque

D: I think that's what Robin is saying too & i agree

J: I'm fine with fixing that just not sure how

D: something more constraining but still vague.. under certain circumstances / when absolutely necessary ..

J: we could copy GDPR.. legitimate as long as strictly necessary

N: are we losing context? The principle still says if a service _needs_ to collect extra data it has to take extra technical and legal measures. I'm not sure we need this in the later paragraph. Later paragraph was just to say you should explain it, and the concern was about providing detail. We could remove the legitimate thing.

J: I'd be fine with moving the legitimacy part but we don't say that anywhere. We say sometimes services do this and we never say what we think is okay. Feels like we're restricting things beyond what the newest regulations are restricting things

N: there are lots of okay things we don't say are okay

J: the PR would be an improvement even without the "legitimate" text, but I'll probably try to add it somewhere. Also I got conerns about the principle being very specific and maybe we should invert which paragraph is the principle. I'm looking to rejigger this in another PR.

N: I like the idea of a general principle for purpose limitation, which maybe we don't have

J: now ready to merge?

## [PR 246: consent indicators](https://github.com/w3ctag/privacy-principles/pull/246)

J: rewrote the text. Still have a concern from Michael that consent should be rare, intentional and temporary. That is not what regulations require. Do we want to write a should that everyone is going to violate? I think we can delete the last sentence.

N: are you saying the law requires vilating this?

J: in practice everyone asks for cookie consent. Storage allowed when strictly necessary for operation.. but everyone thinks they need to ask consent. We have evidence in practice people will be asking for consent all the time, do we want to say they should not do that

D: yes

J: i'm fine with that conclusion. I think the rest of this text fixes the concrete problem

D: it should be aspirational

N: this wouldn't actually say that requesting consent should be rare

J: though maybe it should

N: yeah

J: merge as is? and keep thinking on improvements

N: just in terms of making the arguement.. we're saying in general providing consent should be rare. We should get to we should make it easy to automatically say no




