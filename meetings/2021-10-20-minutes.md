# TAG Privacy Task Force Minutes - 20 October 2021

Present: Dan, Amy, Pete, Don, Jeffrey, Christine

Regrets: Robin, Tess

## Minutes

### [People & Data style improvements](https://github.com/w3ctag/privacy-principles/pull/30)

Jeffrey: not updated since last time we talked

### [Qualify user agent responsibilty](https://github.com/w3ctag/privacy-principles/pull/65)

Don: covering just the data interchange of which the user agent is aware

Dan: we talked about this and you rebased it after our call last time. This is something we could just merge? We already talked about it. Robin was here, we all agreed.

Jeffrey: +1

Dan: [merges]

### [Remove "out of band"](https://github.com/w3ctag/privacy-principles/pull/67)

Dan: Jeffrey approved it, looks small, okay to merge?

Don: just took out 3 words that aren't needed

Dan: you're right [merges]

Don: issue about it can be closed

### [open issues](https://github.com/w3ctag/privacy-principles/issues)

#### https://github.com/w3ctag/privacy-principles/issues/68

Dan: sympathetic to the point about not everything is enthusiastic.. brought to mind that not everyting is about customer "delight". Desigining a system so people could arrange prison visits use case.. or even more mundane things like car registration or stuff like that. Plenty of situations in which one does not give "enthusiastic" consent

Jeffrey: since FRIES originally comes from a sexual consent perspective there's also sex work where someone is being paid for sex, we don't want to say that's unethical but it doesn't fit into this framework. I'm wondering if planned parenthood or a sex worker organisation has some framework where you're trading something that you could give away for free but it's actually a transaction. Does that give us any insight into use of personal data? I wouldn't use that analogy in the document but it might be informative.

Dan: might be better to wait until Robin is back

Christine: I think that would be helpful. Also before we get to what cosnent should look like which is a topic of heated discussion in gdpr and many privacy frameworks, the first point is I think there's an overreliance n consent to achieve purposes.. if I had my way a business would have to establish the legitimate business use first before asking consent, not use them as an alternative.

Jeffrey: is funding a legitimate business use?

Christine: that's the age old question. I guess it would depend on the circumstances becuase people say the web would not exist without advertising, but we don't know that that's true, it's just the way it's developed. There might be other models that could provide funding without the need to do tracking and advertising

Don: and of course advertising has a bunch of different flavours, some are tracking based and others aren't. Comes back to what is the user agent aware of? Because let's say the activity is I'm buying a $200 gift card and sending it to someone. That might be someone you enthusiastically want to do or it might be paying off a ransomware payment that happened in another application and the ua has no idea that this thing represented as a happy gift is osmething that's not a legitimate business activity that you are not freely choosing to do.

Dan: the other things this brins to mind is we've had a lot of discussion in the TAG that might help to inform this, about if there is some kind of privacy infringing activity or technology that the user is about ot enable and the specific thing that came up recently was webxr raw camera access api where yu're trying to enable an agumented reality session and you want to give the web app raw camera access, means the web app can see everything your camera can see, the need for this is to be able to pipe that access to eg. an image recognition thing that is trying to recognise the presence of certain ar markers so it can render cute animals, or it's recognising faces so it can draw funny hats, now you've just given the ability to do facial recognition to whoever owns that ar application. Conversely the regular ar mode, the web app knows about the gemotry of the room but doesn't have access to the raw camera feed. In the case of the web ar/xr module you're already having to answer a prompt saying "would you allow this to go into ar mode" so now with the webxr raw camera access the question came up what more prompt can we give the user that explains to them that this is even more dangerous activity and potentially more privacy infringing and we're having a special session to talk about this, because it doesn't feel like there is anything more. Especially if you're sitting down at a restaurant table with your friends and there's a qr code that says scan this to add funny faces.. you want to have the funny faces, you're going tp ush through the prompt no matter what. At some point the web also needs to intrinsically protect the users privacy rather tahn rely completely on prompts. We can't say prompts are the answer, they're necessary but not sufficient. We can't just make the prompt more scary, people get inured to that. That is to say at some point the web needs to do something which is inherantly be more privacy preserving. The choices the web xr group chose to make about the xisting web xr ar module was specifically to not allow access to the camear feed because it was privacy infringing. One of the things we'll have to discuss is what oculd they do to migitgate against this privacy issue intrinsically within the api itself, like fuzzing or disallowing access to other things> What could they be doing? and I think one of the things I'd look to from this doc is to be able to articulate sometimes you need to design the api to intrinsically resist privacy infringing activity, prompting is not the only answer. I do'nt know that we have wording in here that says that.

Jeffrey: the same issue that Christine brought up.. want legitimate interest/need .. can't really tell that. One thing we have tried to do in some apis is allow the user to say no but pretend to the website they said yes. Produce fake data or something, so it's not trivial for the website to block access when the user said no.

Dan: in the case of webxr I don't know what mitigations. But eg. in some cases with other apis they specifically add fuzzing to data in order to mitigate against fingerprinting. 

Jeffrey: with geolocation it would be straightforward to let the user give a fake location. We could allow the user to provide fake data prevents them from being forced to consent by withholding access to the thing they want if they don't consent. Appropriate to say something about preventing forced consent.

Christine: sounds really good. I shared earlier a link to a website (https://darkpatternstipline.org/harms in https://github.com/w3ctag/privacy-principles/issues/35) that keeps track of dark patterns that services and websites use to trick users into consenting or not realising what's happening.

Dan: the one that always springs to mind is the notification permission prompt that comes up with an arrow pointing saying click okay to prove you're not a robot which relies on the training we've already given people that they should click something to prove they're not a robot, but in this case they're providing consent to being spammed, which is not a privacay issue but certainly a user safety issue. Mature discussion around consent, not necessarily in the legal sense, but prompts, how well they work.. how much research can we point to about this? There's a lot of talk .. people like phrases like permission promts don't work and stuff, there's science out there somewhere.. would be useful to funnel some of that into this doc

Jeffrey: we have some data on how often .. how often do people click through, yes/no/ignore on all of the different permission prompts, and they're very different. Not useless either.

Dan: that kind of fits with my mental model of how they work and don't work. There is something useful there. Another anecdotal thing - the thing with how when apple rolled out the privacy features on iphone there were a lot of people that did not allow ad tracking. Of course that's not quite the same thing, because they weren't being told "allow ad tracking and you can have the cool thing" and in the absance of any incentive they click no

Don: apps were allowed to present a screen and an argument to try to get people to click through. The apple tracking prompts were probably the closest to a fair choice of any tracking consent UI so far.

Jeffrey: look at how apple worded their prompts differently when it was themselves vs third parties

Don: they made a completely different preference for the apple tracking and third party apps tracking

Dan: is there a comprehensive article that we could reference on that?

Jeffrey: I haven't seen anything that said what the result was, what fraction of people accepted apple tracking

Don: I could probably find an article about tips to get your users to agree..

Dan: how should that flow into our document?

Jeffrey: a distinction between what websites should do, and what browsers should do to protect users from websites that don't. And the other thing to do is [... lost audio ..] say no without losing access to the feature. FRIES isn't quite right, but I think there is guidence.. something along the lines of what Christine suggested.. you should have a .. for this information. What legitmiate needs are?

Christine: I don't think we need to becuase I think that's a decision that can be made by the company and then by privacy researchers and data protection authorities. An org can say we had a legitimate need and others can say no you didn't. Enough to just say the need.

Jeffrey: I'm nervous about that feedback loop, but if you think it works

Christine: in this document I don't think we need to give guidence to websites on what is a legitimate need. I think that guidence can come externally.

Jeffrey: yes. I guess there is case law on what the gdpr statement means

Christine: I'm sure there is. the concept has been around in the directive for a long time. Even though other juristidctions don't use that terminology, they might use "reasonable" I'm sure there have been a lot of cases where companies have done things and said they had a legitimate need and have been challenged n it

Jeffrey: That makes sense.

Dan: where in the doc do we talk about mitigations within the web platform beyond consent? In user agents?

Jeffrey: so far the section that talks about .. identity on the web in particular talks about "websites should nto recognise users across contexts" ...force that across partitions. We can make the same kind of..

Dan: okay

Jeffrey: might be a rewrite of 2.8, how users should be able to consent to stuff. User control section.

Pete: not go too far into being prescriptive. Some of this is in s&p questionnaire, principles doesn't need to give solutions

Dan: agree

Jeffrey: The principle might just be that user agents should ensure that users have a true choice, can't be coerced by withholding acces to the feature

Pete: +1

Dan: is that a PR?

Jeffrey: I'll try to write something


