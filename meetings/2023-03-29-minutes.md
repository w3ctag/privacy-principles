# TAG Privacy TF Minutes

Present: Dan, Jeffrey, Christine, Tess, Robin, Nick, Wendy

Regrets: Sam, Don

## [sarcasm](https://github.com/w3ctag/privacy-principles/pull/234)

Robin: this makes the doc more dry and less readable but not opposed.

Nick: substantively I've wanted a change like this. I don't think it's just because of the change since the 1970s...

Jeffrey: arguably..

**agree to merge**

## [236](https://github.com/w3ctag/privacy-principles/pull/236) / [242](https://github.com/w3ctag/privacy-principles/pull/242) on purposes

duelling PRs

Robin: both replace the idea of burden of proof - which evokes cours - with the idea that actors should take care of consent. The difference is that jeffrey keeps it about purposes but remove sensitive - i keep sensitive but make it about processing....

Jeffrey: I don't feel strongly about the *sensitive* bit. I think if we talk about processing we would need a matching bit in the first para.

Robin: i feel that's fair.

Jeffrey: we also suggested different text for processing last week... if we stay with processing we should take the text we talked about last week. https://github.com/w3ctag/privacy-principles/issues/229#issuecomment-1479981172

Robin: that text works for me...

Nick: looking at purposes vs processing - looking at opt in/ opt out def... only thing changes is number of purposes... it's not right...   So I like Robin's PR plus jeffrey's amendment.

Jeffrey; I'm fine with that.

**we agree to progress/update 242 and deprecate 236**

## [Remove "unprecedented"](https://github.com/w3ctag/privacy-principles/pull/237)

Dan: I support removing

Christine: Me too.

Robin: for the record I disagree...

Dan: maybe another phrasing?

Robin: the reason is not for emotional purposes - I do think it's unprecedented - and trying to apply balancing that may have worked previously may not work.

Nick: i think the strength is valuable - but in this case there are precedents - we know concentration of power is bad because of precedents.

Jeffrey: master switch also has concentration of power in media - we should be learning from those...

**agree to land this PR**

## [opt in / opt out](https://github.com/w3ctag/privacy-principles/pull/237)

Robin: the idea is that if you have an automated signal then you need a general rule of which matters most. If you you get the rule wrong then bad things. If we grant web sites to override an automated signal then we proliferate the cookie banner problem. The user delegates power to the agent to say "no" when there is a request...  When i discussed with lawyers - it takes precedence.

Nick: I like that point about the automation asymetry - this PR doesn't change that.

Robin: I'm fine re-formulating in a way that might be clearer...

Jeffrey: delegated to automated agent... that can't make contextual decisions... if on a particular site you have the option to opt back in (e.g.). general/specific consent what does it mean?

Robin: Ideally it shouldn't be an imposition on the site - it should be on the browser. you should have a way to tell the browser "for this site, disable" - that takes precedence. I think this is worth some wordsmithing.  The idea is to stop people coming up with regulation - turns an opt-out signal into cookie spam.

Nick: we discussed last week that the current text could be interpreted as going back to a DNT - any change of the opt out should be mediated through same API -- that wasn't successful. Maybe there's agreement it needs to be more specific... but "has to be mediated by the UA" isn't a productive approach.

Jeffrey: what if I add "sites should not ask to override the opt out unless they have knowledge of the user's situation"?

Robin: I think there's way of making this better but I'd rather not make it a requirement on the sites... maybe somethign like "opt out systems should be designed in a way that constrains sites' ability to override"...

Nick: I was reading it as a requirement on UA and spec design...

Jeffrey: I read it as a statement about regulation...

Robin: **takes action to reformulate it in a way that is more productive**

## [Infra UA def](https://github.com/w3ctag/privacy-principles/pull/239)

Jeffrey: WHATWG spec that defines UA... best to just link to that.

Tess: it's cited by *everything*

Dan: +1

## [not about GDPR](https://github.com/w3ctag/privacy-principles/pull/243)

Robin: ... about how this looks like a statement about GDPR...  It's not legal advice... just talked about regimes in general...

Dan: this looks good to me.

Jeffrey: we shouldn't use legal terms... so I'll double check...  concern about "legitimate interest"...

Robin: this not just about consent...

Nick: maybe we don't need legit interest...

## [ancilary data](https://github.com/w3ctag/privacy-principles/pull/221)

Pete: still would like to remove this...

Nick: maybe we can resolve - is your concern we're using "may" would get interpreted as 2119 may? "this is allowed" ...? minimize privacy labour?  If we change it to might?

Pete: if it's just stating a thing that might happen in the world then just drop it?

Robin: this seems to be endorsing things that might be missued? In that sense I agree it's better to say nothing... Might is better than may, agree. But I still think suggesting it's a done thing is problematic.. I agree with Pete - rather say nothing.

Jeffrey: I think some UAs will want to do this because there's some ancillary data that nearly all of our users are OK with so increasing promt blindness by asking everyone will be bad. If we agreesively avoid ancillary data and avoid privact labour then that says "don't send it and don't ask them"...

Pete: that's exactly the concern - people will enable things in ways that users don't understand...

Jeffrey: that's a legit difference between user agents... People who want their UA to ask them about everyhing will choose (one browser) and those who don't will use (another).

Wendy: without more expansion the sentence could be "we'll do what's right for the majority of users" which is problematic for users on the margins...

Jeffrey: we could add "don't exclude people who are marginalized"...?

Robin: putting this to the UA assumes that people have knowledge... to make settings... people don't have information to make this choice.  If we want to open the door... uncomfortable granting powers to dangerous processing based on user research that's done by the people who are doing the thing they are researching... The Nytimes has research that says NYtimes readers are fine with advertisers that nytimes pics... does that mean users are fine sharing data with advertisers?

Pete: one reason for this doc is to provide structure for reviews - having a "we did user research" escape route feels undermining...

Robin: how would you feel if the the argument that there was user research was backed by real user research...

Dan: *talks about how TAG requests user resarch sometimes*

Pete: i can see how user research is important... it's a wide field... it's not easy to not know the difference...

Robin: i lean towards what pete said.. i'm looking for ways of finding mitigations...

Jeffrey: i like robin's suggestion that user research gets validated outside of the vendor... I will go back to Yoav Weiss (as a voice who advocates that sometimes you have to send data without asking) in web perf... ask about this issue and what we could say that might be acceptable...

Dan: "first use" request scenario?

Nick: more specific.. privacy labor... any ideas on how to be more specific...

Jeffrey: the core of the disagreement is when to ask the user...?

## [Duty of Loyalty](https://github.com/w3ctag/privacy-principles/issues/241)

Nick: it seems like Jeffrey looks at this citation - hurting an individual to benefit someone else - the txt we have is benefiting someone else to hurt the user.. there may be things that do benefit someone else but don't hurt the user - and that should be OK.

Jeffrey: we've said that ... benefits to other parites...   Academics also have 2 different levels of self-dealing as bad... I think I'm fine with us using the 2nd def.

Robin: I think they use both definitions... because a broad def is more scary...  If we're talking about narrow chanegs to make it for the benefit for the browser - the entrustee - then I can do that... make that change.

Jeffrey: I think that would be sufficient.

*legal discussion*

Pete: is the question whether it violates the duty of loyalty ... there's nothing you can do on my computer that doesn't cost me something...

Robin: if you process data .. you increase risk.

Jeffrey: 2 divergences ... group privacy - sometimes the browser needs to act in the group's interest.

Dan: e.g. safe browsing...
