# Privacy Taskforce meeting

13 Octover 2021

Present: Dan, Don, Jeffrey, Amy, Robin, Sam, Wendy, Jonathan, Pete, Christine, Tess


Scribe: Jeffrey

# PRs

## [People & Data style improvements](https://github.com/w3ctag/privacy-principles/pull/30)

Jeffrey: I had suggested making it dramatically shorter, and want to hear what the rest of the group thinks.

Robin: Could live with the simpler deifnition of personal data. Tried to make it more precise because there are pitfalls with the simpler definition, but also obvious that there are pitfalls with being more precise.

[Issue 48](https://github.com/w3ctag/privacy-principles/issues/48) also requests the older definition.

Christine: I'm inclined to stay with the simpler definition. More people understand that.

Robin: Lukacs wants us to adopt the GDPR definition, which is in line with Christine's comment.

Dan: Let's go with that.

Robin: Making a note of that in the PR.



Jeffrey: I made a similar "simplify this" comment on pseudonymous data, which I hope can avoid lots of detailed comments.

Robin: Tried to make the definitions precise to avoid misunderstandings. Might work better to have a simpler definition and then discussion about "readers should be aware that pseudonymous ... has had issues with things". Instead of trying to make a strict definition.

Dan: Would adopting the new text close #48?

Robin: Yes.

## [add initial draft of section on unexpected profiling, fixes #27](https://github.com/w3ctag/privacy-principles/pull/38)

Pete: I think I've addressed all the comments. Pulled some controversial text and preserved it in other issues. Only one without a crisp answer is about the purpose of the example.

Robin: About the furries?

Pete: Not wedded to this example, but want something that's sensitive to some folks and not to others.

Robin: We had agreed to separate unexpected inferences from ... as long as this is clearly unexpected inferences it's fine.

Dan: Point about citation: "contributing to feelings of powerlessness and loss of agency": is there some Pew-ish study or NYT article that can underpin that statement?

Jeffrey: File an issue for that. Let's get the rest merged.

Robin: Agree. Julie Cohen would be a good source. I'll dig.

Wendy: A potential reference: https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/


## [Removing fiduciary](https://github.com/w3ctag/privacy-principles/pull/55)

Dan: Is this ready to merge?

Jeffrey: I left a bunch of nitpicky issues, but then yes.

Dan: I like Jeffrey's changes.

Christine: Reading through Jeffrey's comments. In the section on honesty, we might add "choice". "Information that's relevant to them, that increases their autonomy." I don't see "choice".

Dan: Can we add an issue about that? So we can merge this? A "duty of offering choice"?

Christine: Might not characterize this as a duty, but I'm concerned that users are told "if you want to use this, you have to accept all these conditions." 

Robin: This section's about the user agent.

Christine: Ah, I thought this section was about both actors.

Robin: There's no notion of fiduciary beyond user agent fiduciaries in the document.

Christine: That clarifies things.

Robin: Removing the paragraph on paternalism. It doesn't add much.


Jeffrey: I think we can't extend fiduciary duties to everyone on the web.

Robin: There are some laws that start extending fiduciary duties to people who store data. Something about not being able to use what you know about people to decieve them. We could think of some duties for other actors, beyond UAs.

Christine: I see the merit in keeping this scoped to user agents, but this is the W3C saying "these are principles for the web at large", so there's nothing wrong with saying "if you're a good web citizen, as a website owner, you will apply privacy when you interact with the web."

Jeffrey: Yes, it makes sense to say that websites have certain duties to their users; have to be careful about which duties but we can discuss that separately.


## [Qualify user agent responsibilty](https://github.com/w3ctag/privacy-principles/pull/65)

Don: This touches the same text as previous ones, although Git thinks it merges. Want to double-check that Git didn't create new syntax that does different things.

Jeffrey: Robin hasn't quite merged #55, so Github can't see that collision yet.

Don: Let's review the substantial changes and then have a `git` dance-off.

Dan: Some hedging language about "can be reasonably aware".

Don: UA isn't responsible to go out and gather data about the companies behind the sites it connects to.

Jeffrey: I didn't double-check that this is everywhere that needs this language, but the changes are good. Let's merge this.

Jonathan: Of two minds: this is an improvement in describing what UAs can do, but in an ideal world it would be able to do these things.

Dan: But e.g. UA's not responsible for data sharing that's behind the scenes the UA can't see.

Pete: Worried that if you're getting data from somewhere else, it's unenforceable from the client. Maybe the client shouldn't trust servers for privacy properties; shouldn't rely on other parties?

Christine: Two ideas: what's in #65, and also what Pete has said. Some of this looks like we're writing a legal document. UAs want signaled that they're not responsible for what sites do. But also important that UAs not trust the servers.

Don: Can we codify that? That resonates: the UA is on the side of the person using it.

Tess: That's something inherent to client-server situations. Clients in general can't trust what servers do. They can claim they're doing whatever they want.

Dan: Can we accept Don's PR and work on separate text to capture that?

Jeffrey: I think yes. We have an assumption throughout that servers aren't trustworthy.

Dan: But we should have a sentence saying it.

Jeffrey: Yes.

Jonathan: With that sentence, does #65 add any value?

Jeffrey: I think yes: these blocks were saying UAs need to do things they can't do with current technology, so these additions make the sentences true.

Jonathan: Worried about the document looking like legalese.

Dan: Agree with that concern; I think these particular changes are still needed.

Don: Rebasing manually and will merge afterwards.


# Issues

## [Go through list of suggestions from the WebAdv "success criteria" that some had proposed](https://github.com/w3ctag/privacy-principles/issues/61)

Robin: A while ago some participants in the WebAdvBG suggested these ["success criteria"](https://github.com/w3c/web-advertising/blob/main/success-criteria.md#interests-of-society). Last week I took on the action item to extract pieces we need to include. Left a [comment](https://github.com/w3ctag/privacy-principles/issues/61#issuecomment-936869462) with my impressions. Things we should add:

* Freedom from having to self-censor 
* Data subject rights
* Algorithmic explainability, but this is probably too big to fit in this document.


Christine: Thank you Robin for going through that document. You mentioned interoperable standards of communication. We see legal jurisdictions bringing in data portability. We don't want to get too much into data portability, but we could say that the whole point of W3C standards is that they're interoperable, so they help with data portability.

Christine: Thanks for identifying the risk of users self-censoring. After Snowden, there was research on people self-censoring in Google searches. Agree that algorithmic explainability is a can of worms. Rather than algorithmic explainability, maybe think about what interacts with W3C standards, and what visibility users have. Comes up with EPub. EME. Machine Learning models.

Don: A lot of the tension of the WebAdvBG, we get into the weeds when talking about moving a non-transparent market mechanism into a user agent. One company has a 4-level neural net that uses the user's battery to influence some piece of advertising. When the UA is the thing that makes the decisions, the discussion in the WebAdvBG has to be rebased onto that. (The user agent is supposed to make the decisions that the user would if they had time to process the same information)

Dan: On the topic of being the interface to opaque things. On EME, the TAG wrote https://www.w3.org/blog/2015/11/strong-web-platform-statement/ supporting that having a thing with strong auditing keeps the web's privacy guarantees  intact.

Christine: Let's consider incorporating this sentiment into the document as a privacy design feature.

Dan: "The web should not prevent privacy researchers ..."

Christine: "privacy researchers need to be able to see what is going on"

Wendy: There are lots of things to potentially say. I'm not sure this document can contain all the things we might want to say about things that deny researchers access to information. I take the high-level policy point. User privacy is enhanced by a research community being able to give them more background about what's going on in their web activity. Is there a way to word that? Users rely on lots of external analyses to set their expectations of the web and make their choices. 

Robin: I think there's something there that fits. I agree that this could be a huge scope creep, and we shouldn't go there, but there's something around transparency that's not directly to the person but through collective accountability. We could mention that without digging into details. In a section on Data Rights. When you make an access request, and you get your data back, it tells you very little about what that company is doing. If you could delegate to another company, a data union, to analyze the data of 100k people, they could learn things. If we really want accountability, we should let privacy researchers see what's going on. User privacy is enhanced by research. Don likes "verified agents".

Don: In California we have that, but GDPR doesn't have authorized agents. See [FPS members must allow technical verification](https://github.com/privacycg/first-party-sets/pull/65). We see the beneifts of delegated aggregation and reporting surfaces in some of these proposals, such as the "Independent Enforcement Entity" in the First-Party Sets proposal. 

Dan: Actionable stuff: I think you wrote 3 bullets.

Robin: I took some notes to remember what to write. I will write a PR that I think can close this issue, and people can see if they want more.

Dan: Should we open a separate issue about loving privacy researchers?

Robin: I was thinking to include that in this PR.

-----

Dan: Triage some issues? Pete?

Pete: I opened a couple that save text that was out of place.

Dan: Don's https://github.com/w3ctag/privacy-principles/issues/64

Don: Can we get rid of "out of band"? Just because the user ignores them and clicks the big green button doesn't mean they don't have concerns.

Dan: Does the text mean to refer to paper agreements? E.g. "The customer agreed when they bought their phone"

Don: Just think we can remove "out of band".

Dan: Do a PR.

Dan: https://github.com/w3ctag/privacy-principles/issues/62?

Jeffrey: We've made progress on this when we touch issues, but this is a placeholder to remind us to do it everywhere, in the same vein as the "follow the style guide" issue.

[Discussion of whether to meet during TPAC: yes we'll meet.]


























