# TAG Privacy Taskforce - Wed, 3 May 2023

## Attendees

* Sam
* Robin
* Dan
* Nick
* Pete
* Wendy
* Don
* Jeffrey
* Christine
* Amy

## Discussion on "Transparency"

Nick: Do we need more on transparency in the doc?

Robin: maybe raise an issue - maybe we could say more about transparency to individuals...

## https://github.com/w3ctag/privacy-principles/pull/221

Pete: I think Jeffrey was going to check on this... feedback?

Jeffrey: I think this raises concerns... if we think there's some ancilary data its ok to send to sites... the way we decide of which things to send is by doing user research - and figure out what invates privacy the least.

Pete: ... how can we turn those into reviewable criteria?

Jeffrey: don't have a list of what constraints we put on this... 

Pete: ... to document in the issue... some kind of bounds around user research... what kikind of research ...

Jeffrey: might be a good thing to ask the web perf working group in general.

## 236 and 242...

*We agree to defer*

## 238 -

*pending robin's rewrite*

## https://github.com/w3ctag/privacy-principles/pull/262/files

Wendy: looked fine to me  - 

Robin: makes sense - makes it more readable...

Dan: Merge?

Jeffrey: *clicks button*

## Acknowledgements

Robin: I will check that this is up to date.

## Wide Review

Nick: we asked people to give us feedback by end of April - we got some... A fair number in progress... Have we individually reached the groups we were planning to?

Christine: can we extend to end of May?

Nick: no formal deadline...  We got a detailed review from ChrisN...

Christine: I wonder if any of the horizontal groups have looked at it?

wide review outreach update: https://github.com/w3ctag/privacy-principles/issues/217

Pete: let's prod the a11y folks

Sam: if we want a11y or i18n we should ask for that through their processes...

Jeffrey: we can present this to the PING.

Dan: additional TAG review pending as well...

* we agree to extend the review period to end of May *

## https://github.com/w3ctag/privacy-principles/issues/260

Jeffrey: We have a dfn for principle... meaning of principles is not clear... fix is just to remove the dfn.

Robin: yes I think this is fine... removing the dfn is good enough...

*so fine*

## Issue 256

Christine: I don't like "resolving tensions".  "Using"?

Jeffrey: original title was balancing...

Christine: can we have applying?  I don't want balancing or tension in the heading...

Don: I don't like balancing (leads to too many rat-hole discussions about trading off privacy) 

Jeffrey: I think we don't have consensus to say "balancing" or "tension" in the title so we should just reject chris's suggestion.

Jeffrey: I think the 2nd point does require a PR...

## https://github.com/w3ctag/privacy-principles/issues/261

Don: not addressed in the web without 3p cookies doc but a big concern with some practical mitigations now in progress - attempts to replace 3p cookies with something with better privacy properties... scaling properties of 3p cookies easier to reason about. one post-cookie privacy measure is adding noise to cross-site tracking info - but as long as you're adding same amount of noise to all cross-site tracking then you're making it easier for a 3rd party that has more of that noisy data to get info on groups of people than a third party that has less of that noisy data. A lot of privacy threats that are group related.... such as applying a discrimitatory polciy to members of a certain group... as long as actors continue to try to do them they will be more incentivised to rely on larger 3rd parties... pushes towards centralization risk.

Dan: I wonder if there's a general principle about noise that would address this and other areas where somebody might say in a design "we'll just add noise". I've seen that a lot. Is there osmething where we can say when your design involves adding noise as a privacy mitigation, here are some issues that you should consider.

Jeffrey: feel this belongs initially in the PATCG's privacy document. Right now we don't have anything about noise or mathematical techniques people use for privacy in this doc. If we can generalise them into something that is not about particular mathematic techniques not used for advertising it might belong here.. but as specific as this issue belongs in PATCG.. who might come up with something we could extract into this doc.

Pete: Mostly agree. I don't think it should go in this doc. I don't like the idea of it in the PATCG doc. Design Principles or something like that. Web Perf folks might want something like this, and other places it might be useful. We might not point to something in PATCG in platform reviews

Jeffrey: I think PATCG has sthe right expertise for it. Even stuff web perf might adopt is being invented in PATCG. When they come up with something we can extract it to somewhere more central. Even just in PATCG, privacy reviews should be willing to cite their privacy doc.

Christine: Should something go in the Questionnaire - security and privacy?

Dan: there's nothing currently in it https://w3ctag.github.io/security-questionnaire/ - so this might be a good idea.

Pete: I can work with Tess on that

Don: there's probably some commercially sensitive info in here.. statistics for extracting group discrimination data from noisy user data are probably trade secrets that we may  not have much visibility into.

Jeffrey: but we know they exist. We can talk about the existence without the details.

Don: but we need to know enough to know how good they are in order to .. if noise is going to be added on the client, noise has to be added in such a way as to address centralisation risks. If you don't know how good somebody's trade secret group discrimination algorithm is ou don't know how much extra noise is appropriate to add on the client for large third parties

Jeffrey: My understanding was the differential privacy work was about establishing mathematical bounds on how much information exists regardless of how good the algorithms are. Supposed to tell us how much noise we need to add given traffic numbers for the large entities, regardless of algos.

Don: DP has been focusing on reidentifying users as individuals with a reasonably high level of accuracy. That's not the group discrimination issue that needs to be addressed. Differential privacy can be mathematically proven that I can't pick you out of a crowd, but there could be some math that's good enough to say 90% of the people in this group are not going to get this offer or whatever

Jeffrey: research beyond differential privacy that needs to be done?

Don: there's demand for group level discrimination and there's unknown noise amelioration work happening

Wendy: more than just the individual identification information. Some of it may be additional mathematical analysis and others.. differential privacy isn't the only thing looking at protecting agaainst consolidation

Dan: I"m going to add a [question about noise in an issue in the S&P questionnaire](https://github.com/w3ctag/security-questionnaire/issues/154) repo, and link it back. I think that some of the discussion about mathematical nature of noise... feels like we need a qualitative principle, rather than have you considered x, have you considered y, are you making sure your strategy around how you're using noise takes into account the centralisation aspects that are important. Rather than .. the specific more detailed quesiton could be brought up in the PATCG.

Jeffrey: I think the PATCG needs to lead on it. I don't think most of us here have the expertise to dig into the gritty details. Having a general principle about considering centralisation effect makes sense somewhere... but not in privacy. More ethical web?

Dan: we're going to have to revisit the S&P questionnaire in light of this document anyway.

Pete: Sounds great. Against the PATCG leading is they are very opinionated about this and differential privacy is not a magic wand, and in some ways requires centralisation to be useful to understand the distribution. Not a complete way of thinking about it. DP is a solution in a wawy I haven't seen PATCG engage with on.

Don: I do think there's an overlap between centralisation rsisk and privacy risks. As an individual in one country you might be more willing to have your data available to a variety of smaller actors or parties in other countries, than held by a state owned corporation in an extremely large country. Let's not automatically separate centralisation risks from privacy risks.



